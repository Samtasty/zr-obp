{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc08c2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import tqdm\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d71fdf67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4df01452",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'good_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpickle\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mgood_list.pkl\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mwb\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[0;32m----> 3\u001b[0m     pickle\u001b[39m.\u001b[39mdump(good_list, f)\n\u001b[1;32m      4\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39m'\u001b[39m\u001b[39morderprob.pkl\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mwb\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m      5\u001b[0m     pickle\u001b[39m.\u001b[39mdump(df\u001b[39m.\u001b[39mproblem, f)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'good_list' is not defined"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "with open('good_list.pkl', 'wb') as f:\n",
    "    pickle.dump(good_list, f)\n",
    "with open('orderprob.pkl', 'wb') as f:\n",
    "    pickle.dump(df.problem, f)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5b31e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('attempts.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a19ef220",
   "metadata": {},
   "source": [
    "the problem 25 is never given to a student so we can replace the name of problem 86 with 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84ee4a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.problem=df.problem.replace(86,25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b6ba4b53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>student</th>\n",
       "      <th>problem</th>\n",
       "      <th>start</th>\n",
       "      <th>solved</th>\n",
       "      <th>time</th>\n",
       "      <th>n_edits</th>\n",
       "      <th>n_executions</th>\n",
       "      <th>program</th>\n",
       "      <th>problemset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>2017-11-10 12:20:05.152265+00:00</td>\n",
       "      <td>True</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>lrf</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>29</td>\n",
       "      <td>12</td>\n",
       "      <td>2017-11-10 12:20:32.155447+00:00</td>\n",
       "      <td>True</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>rrff</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>29</td>\n",
       "      <td>10</td>\n",
       "      <td>2017-11-10 12:20:54.080259+00:00</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>sff</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>29</td>\n",
       "      <td>14</td>\n",
       "      <td>2017-11-10 12:21:06.966330+00:00</td>\n",
       "      <td>True</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>frl</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>29</td>\n",
       "      <td>11</td>\n",
       "      <td>2017-11-10 12:21:33.061485+00:00</td>\n",
       "      <td>True</td>\n",
       "      <td>27</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>R4{fs}</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285806</th>\n",
       "      <td>308258</td>\n",
       "      <td>32173</td>\n",
       "      <td>50</td>\n",
       "      <td>2020-10-01 17:22:44.928241+00:00</td>\n",
       "      <td>False</td>\n",
       "      <td>5689</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>R4{l}R2{r}</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285807</th>\n",
       "      <td>308259</td>\n",
       "      <td>32252</td>\n",
       "      <td>51</td>\n",
       "      <td>2020-10-01 17:24:41.451870+00:00</td>\n",
       "      <td>True</td>\n",
       "      <td>42</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>fff</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285808</th>\n",
       "      <td>308260</td>\n",
       "      <td>32252</td>\n",
       "      <td>44</td>\n",
       "      <td>2020-10-01 17:25:27.317684+00:00</td>\n",
       "      <td>True</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>lff</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285809</th>\n",
       "      <td>308261</td>\n",
       "      <td>32252</td>\n",
       "      <td>14</td>\n",
       "      <td>2020-10-01 17:25:47.455266+00:00</td>\n",
       "      <td>True</td>\n",
       "      <td>74</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>frl</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285810</th>\n",
       "      <td>308262</td>\n",
       "      <td>32252</td>\n",
       "      <td>66</td>\n",
       "      <td>2020-10-01 17:27:04.676229+00:00</td>\n",
       "      <td>False</td>\n",
       "      <td>40</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>285811 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  student  problem                             start  solved  \\\n",
       "0            4       29        2  2017-11-10 12:20:05.152265+00:00    True   \n",
       "1            5       29       12  2017-11-10 12:20:32.155447+00:00    True   \n",
       "2            6       29       10  2017-11-10 12:20:54.080259+00:00    True   \n",
       "3            7       29       14  2017-11-10 12:21:06.966330+00:00    True   \n",
       "4            8       29       11  2017-11-10 12:21:33.061485+00:00    True   \n",
       "...        ...      ...      ...                               ...     ...   \n",
       "285806  308258    32173       50  2020-10-01 17:22:44.928241+00:00   False   \n",
       "285807  308259    32252       51  2020-10-01 17:24:41.451870+00:00    True   \n",
       "285808  308260    32252       44  2020-10-01 17:25:27.317684+00:00    True   \n",
       "285809  308261    32252       14  2020-10-01 17:25:47.455266+00:00    True   \n",
       "285810  308262    32252       66  2020-10-01 17:27:04.676229+00:00   False   \n",
       "\n",
       "        time  n_edits  n_executions     program  problemset  \n",
       "0         24        3             2         lrf           2  \n",
       "1         19        4             1        rrff           5  \n",
       "2         10        3             1         sff           4  \n",
       "3         18        3             1         frl           3  \n",
       "4         27        4             1      R4{fs}           7  \n",
       "...      ...      ...           ...         ...         ...  \n",
       "285806  5689        9             2  R4{l}R2{r}          13  \n",
       "285807    42        5             3         fff           1  \n",
       "285808    16        3             2         lff           2  \n",
       "285809    74       18             4         frl           3  \n",
       "285810    40        8             1         NaN           3  \n",
       "\n",
       "[285811 rows x 10 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feff41ae",
   "metadata": {},
   "source": [
    "We do a classic logistic regression to find the IRT parameters to rename the problems by their difficulty ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d10ea67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 1)\t1.0\n",
      "  (0, 20557)\t1.0\n",
      "  (1, 1)\t1.0\n",
      "  (1, 20567)\t1.0\n",
      "  (2, 1)\t1.0\n",
      "  (2, 20565)\t1.0\n",
      "  (3, 1)\t1.0\n",
      "  (3, 20569)\t1.0\n",
      "  (4, 1)\t1.0\n",
      "  (4, 20566)\t1.0\n",
      "  (5, 1)\t1.0\n",
      "  (5, 20556)\t1.0\n",
      "  (6, 1)\t1.0\n",
      "  (6, 20558)\t1.0\n",
      "  (7, 1)\t1.0\n",
      "  (7, 20604)\t1.0\n",
      "  (8, 1)\t1.0\n",
      "  (8, 20572)\t1.0\n",
      "  (9, 1)\t1.0\n",
      "  (9, 20563)\t1.0\n",
      "  (10, 2)\t1.0\n",
      "  (10, 20557)\t1.0\n",
      "  (11, 2)\t1.0\n",
      "  (11, 20586)\t1.0\n",
      "  (12, 2)\t1.0\n",
      "  :\t:\n",
      "  (285798, 20580)\t1.0\n",
      "  (285799, 20554)\t1.0\n",
      "  (285799, 20569)\t1.0\n",
      "  (285800, 20554)\t1.0\n",
      "  (285800, 20581)\t1.0\n",
      "  (285801, 20554)\t1.0\n",
      "  (285801, 20563)\t1.0\n",
      "  (285802, 20554)\t1.0\n",
      "  (285802, 20565)\t1.0\n",
      "  (285803, 20554)\t1.0\n",
      "  (285803, 20567)\t1.0\n",
      "  (285804, 20554)\t1.0\n",
      "  (285804, 20574)\t1.0\n",
      "  (285805, 20554)\t1.0\n",
      "  (285805, 20575)\t1.0\n",
      "  (285806, 20495)\t1.0\n",
      "  (285806, 20605)\t1.0\n",
      "  (285807, 20555)\t1.0\n",
      "  (285807, 20606)\t1.0\n",
      "  (285808, 20555)\t1.0\n",
      "  (285808, 20599)\t1.0\n",
      "  (285809, 20555)\t1.0\n",
      "  (285809, 20569)\t1.0\n",
      "  (285810, 20555)\t1.0\n",
      "  (285810, 20621)\t1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/newenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.01447939 0.98552061]\n",
      " [0.0060792  0.9939208 ]\n",
      " [0.00706871 0.99293129]\n",
      " ...\n",
      " [0.03005869 0.96994131]\n",
      " [0.04542564 0.95457436]\n",
      " [0.12874895 0.87125105]]\n"
     ]
    }
   ],
   "source": [
    "estimators = [\n",
    "    ('onehot', OneHotEncoder()),\n",
    "    ('lr', LogisticRegression())\n",
    "]\n",
    "pipe = Pipeline(estimators)\n",
    "\n",
    "# Just check the encoded variables\n",
    "ohe = OneHotEncoder()\n",
    "print(ohe.fit_transform(df[['student', 'problem']]))\n",
    "pipe.fit(df[['student', 'problem']], df['solved'])\n",
    "print(pipe.predict_proba(df[['student', 'problem']]))\n",
    "cofs=pipe[1].coef_\n",
    "diffik=pd.Series(index=np.sort(df.problem.unique()),data=cofs.reshape(-1,)[-85:])\n",
    "\n",
    "#probably not optimal way to change the value of the exercice\n",
    "scv=diffik.sort_values(ascending=False).index.values\n",
    "po=[]\n",
    "for j in df.problem.values:\n",
    "    po.append((np.where(scv==j)[0]+1)[0])\n",
    "df.problem=po    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e51d8d",
   "metadata": {},
   "source": [
    "a way to keep the difficulty of the exercices for the futur reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b1b50b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('diffikrobo.pkl', 'wb') as f:\n",
    "    pickle.dump(pd.Series(index=np.arange(1,86),data=diffik.sort_values(ascending=False).values), f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bccd452f",
   "metadata": {},
   "source": [
    "We encode the vector for DKT for each student"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "53172255",
   "metadata": {},
   "outputs": [],
   "source": [
    "#start by doing a dataframe of the history success for each student \n",
    "ohe=OneHotEncoder()\n",
    "l=ohe.fit_transform(df[['problem','solved']])\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8614d4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "stud_list={}\n",
    "for j in df.student.unique():\n",
    "    stud_list[j]=df[df.student==j][['problem','solved']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fb9879ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_l={}\n",
    "for j in df.student.unique():\n",
    "    encoded_l[j]=l[stud_list[j].index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8e6d05ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "good_list={}\n",
    "for j in df.student.unique():\n",
    "    m=encoded_l[j].toarray()\n",
    "    good_list[j]=torch.zeros(len(m),170)\n",
    "    for i in range(len(m)):\n",
    "        if m[i,-2]:\n",
    "            good_list[j][i][:85]=torch.Tensor(m[i,:-2])\n",
    "        else:\n",
    "            good_list[j][i][-85:]=torch.Tensor(m[i,:-2])\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226a2d26",
   "metadata": {},
   "source": [
    "Splitting the training set and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2f8844f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mm=np.split(df.student.unique(),3)\n",
    "np.r_[mm[0],mm[1]]\n",
    "train_l={good_list[j] for j in np.r_[mm[0],mm[1]] }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "246333e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_l={good_list[j] for j in mm[2]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e9208c",
   "metadata": {},
   "source": [
    "Code for the LSTM architecture "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8054ef3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, num_questions, hidden_size, num_layers):\n",
    "        super(Net, self).__init__()\n",
    "        self.hidden_dim = hidden_size\n",
    "        self.layer_dim = num_layers\n",
    "        self.lstm = nn.LSTM(num_questions * 2, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(self.hidden_dim, num_questions)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = Variable(torch.zeros(self.layer_dim,  self.hidden_dim))\n",
    "        c0=  Variable(torch.zeros(self.layer_dim,  self.hidden_dim))\n",
    "        out, (a,b)= self.lstm(x, (h0,c0))\n",
    "        res = torch.sigmoid(self.fc(out))\n",
    "        return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "53c30586",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def process_raw_pred(raw_question_matrix, raw_pred, num_questions: int) -> tuple:\n",
    "    questions = torch.nonzero(raw_question_matrix)[0] % num_questions\n",
    "    \n",
    "    pred = raw_pred[questions]\n",
    "  \n",
    "    truth = (torch.nonzero(raw_question_matrix)[0] // num_questions)*(torch.nonzero(raw_question_matrix)[0]>84)\n",
    "    return pred, truth\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9de0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "net(torch.zeros(1,170))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "30b6200c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DKT():\n",
    "    def __init__(self, num_questions, hidden_size, num_layers):\n",
    "        super(DKT, self).__init__()\n",
    "        self.num_questions = num_questions\n",
    "        self.dkt_model = Net(num_questions, hidden_size, num_layers)\n",
    "\n",
    "    def train(self, train_data, test_data=None, *, epoch: int, lr=0.002) -> ...:\n",
    "        loss_function = nn.BCELoss()\n",
    "        optimizer = torch.optim.Adam(self.dkt_model.parameters(), lr)\n",
    "\n",
    "        for e in range(epoch):\n",
    "            all_pred, all_target = torch.Tensor([]), torch.Tensor([])\n",
    "            for batch in tqdm.tqdm(train_data, \"Epoch %s\" % e):\n",
    "                integrated_pred = self.dkt_model(batch)\n",
    "                batch_size = batch.shape[0]\n",
    "                for student in range(batch_size):\n",
    "                    pred, truth = process_raw_pred(batch[student], integrated_pred[student], self.num_questions)\n",
    "                    all_pred = torch.cat([all_pred, pred])\n",
    "                    all_target = torch.cat([all_target, truth.float()])\n",
    "\n",
    "            loss = loss_function(all_pred, all_target)\n",
    "            # back propagation\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            print(\"[Epoch %d] LogisticLoss: %.6f\" % (e, loss))\n",
    "\n",
    "            if test_data is not None:\n",
    "                auc = self.eval(test_data)\n",
    "                print(\"[Epoch %d] auc: %.6f\" % (e, auc))\n",
    "\n",
    "    def eval(self, test_data) -> float:\n",
    "        self.dkt_model.eval()\n",
    "        y_pred = torch.Tensor([])\n",
    "        y_truth = torch.Tensor([])\n",
    "        for batch in tqdm.tqdm(test_data, \"evaluating\"):\n",
    "            integrated_pred = self.dkt_model(batch)\n",
    "            batch_size = batch.shape[0]\n",
    "            for student in range(batch_size):\n",
    "                pred, truth = process_raw_pred(batch[student], integrated_pred[student], self.num_questions)\n",
    "                y_pred = torch.cat([y_pred, pred])\n",
    "                y_truth = torch.cat([y_truth, truth])\n",
    "\n",
    "        return roc_auc_score(y_truth.detach().numpy(), y_pred.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5e4faaaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def save(self, filepath):\n",
    "        torch.save(self.dkt_model.state_dict(), filepath)\n",
    "        logging.info(\"save parameters to %s\" % filepath)\n",
    "\n",
    "    def load(self, filepath):\n",
    "        self.dkt_model.load_state_dict(torch.load(filepath))\n",
    "        logging.info(\"load parameters from %s\" % filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "fcd17618",
   "metadata": {},
   "outputs": [],
   "source": [
    "dkt=DKT(num_questions=85,hidden_size=5,num_layers=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1c6ed3ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/13704 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rh/v2m3z36j1j71mqlvn91zps5c0000gn/T/ipykernel_22841/543832646.py:6: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  truth = (torch.nonzero(raw_question_matrix)[0] // num_questions)*(torch.nonzero(raw_question_matrix)[0]>84)\n",
      "Epoch 0: 100%|██████████| 13704/13704 [01:11<00:00, 192.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0] LogisticLoss: 0.714090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "evaluating: 100%|██████████| 6852/6852 [00:58<00:00, 116.24it/s]"
     ]
    }
   ],
   "source": [
    "dkt.train(train_l,epoch=50,lr=0.02,test_data=test_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "58e0bbc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dkt.eval(test_l)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dfc2726",
   "metadata": {},
   "source": [
    "saving the model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "54a67bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(dkt.dkt_model.state_dict(),'/Users/samuelgirard/zr-obp/weightslstm.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1ffd2043",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d08f8f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "newenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
